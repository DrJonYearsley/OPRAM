#!//opt/homebrew/bin/julia -p 3
#
#!//home/jon/.juliaup/bin/julia -p 7
#
# Julia program to:
#  extract results from model jld2 files 
#  import the multi-year average of degree day model results
#  calculate corresponding anomaly for each year
#  aggregate results across hectads
#  export results to CSV files
#
# The degree day model results are generatde by OPRAM_main_program.jl
# The multi-year average is generated by OPRAM_calculate_average.jl
#
#
# Author: Jon Yearsley  (jon.yearsley@ucd.ie)
# Date: April 2025
#
# =============================================================================
# =============================================================================

# Load the required packages
using CSV
using DataFrames
using Statistics
using Dates
using JLD2
using Distributed
using SharedArrays
using TOML


include("OPRAM_io_functions.jl");
include("OPRAM_processing_functions.jl");


# ============================================================================================
# =============== Import parameter values =======================================================




# Model parameters are stored in a TOML file https://toml.io/en/
if length(ARGS) == 1
    nNodes, run_params, species_setup, paths = import_parameters(ARGS[1])

elseif length(ARGS) == 0 & isfile("parameters.toml")
    nNodes, run_params, species_setup, paths = import_parameters("parameters_future.toml")

else
    @error "No parameter file given"
end

# # Files containing the ID system from Granite.ie
# # This info is used to package the output into separate files
# granite_hectad_ID = "git_repos/OPRAM/data/granite_hectad_defs.csv"
# granite_county_ID = "git_repos/OPRAM/data/granite_county_defs.csv"
# granite_hectad_county = "git_repos/OPRAM/data/granite_hectad_county_defs.csv"



# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Set species parameters from the parameter file (can be more than one species)
if species_setup.speciesStr[1] == "all"
    @info "Importing all species from the species file" * string(species_setup.speciesStr)
    species_params = import_species(species_setup.speciesFile, species_setup.speciesStr[1])
else
    @info "Importing species from the species file: " * string(species_setup.speciesStr)
    species_params = [import_species(species_setup.speciesFile, species_setup.speciesStr[s]) for s in eachindex(species_setup.speciesStr)]
end


# =============== End of parameter setup =====================================================
# ============================================================================================




# # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# # Import granite files to organise hectads and counties
# # Read in the grid data from a file
# hectad_defs = CSV.read(joinpath([paths.dataDir, granite_hectad_ID]), DataFrame);
# county_defs = CSV.read(joinpath([paths.dataDir, granite_county_ID]), DataFrame);
# hectad_county_defs = CSV.read(joinpath([paths.dataDir, granite_hectad_county]), DataFrame);

# # Rename county ID column
# rename!(county_defs, :Id => :countyID)


# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Import location data and thin it using thinFactor
# (needed to add the hectad codes to the 10km output) 
grid = read_grid(run_params, paths.dataDir)

# Create easting and northings of bottom left of a hectad
grid.east_hectad = convert.(Int32, floor.(grid.east ./ 1e4) .* 1e4)
grid.north_hectad = convert.(Int32, floor.(grid.north ./ 1e4) .* 1e4)


# # Add in column with county ID
# leftjoin!(grid, county_defs, on=:county => :County)


# =========================================================
# =========================================================
# Import data for each species and for each time period
# Calculate the anomaly and then save the result at the 1km and 10km scales

for s in eachindex(species_params)

    # Find directory matching the species name in run_params
    regex = Regex(replace(lowercase(species_params[s].species_name),
        r"\s" => "\\w"))  # Replace spaces with reg expression
    speciesName = filter(x -> occursin(regex, x), readdir(paths.resultsDir))
    if length(speciesName) > 1
        @error "More than one species name found"
    elseif length(speciesName) == 0
        @error "Species not found"
    end

    @info "Importing data for $(speciesName[1])"


    # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    # Make directory for the output if one doesn't exist
    if !isdir(paths.outDir)
        @info "        Making directory " * paths.outDir
        mkpath(paths.outDir)
    end

    # Specify the output directory using the species name
    if !isdir(joinpath(paths.outDir, speciesName[1]))
        @info "        Making directory " * speciesName[1]
        mkpath(joinpath(paths.outDir, speciesName[1]))
    end


    # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    # Import the 1km results for the species and years

    # Initialise vector of files to import
    inFiles = Vector{String}(undef, 0)
    yearVec = Vector{Int64}(undef, 0)
    yearStrVec = Vector{String}(undef, 0)
    if run_params.TRANSLATE_future
        # Create vector of files to import for future climates (TRANSLATE project)

        for j in eachindex(run_params.futurePeriod)
            # Find future year from the futurePeriod
            if occursin(r"(2021|2035|2050)", run_params.futurePeriod[j])
                Year = 2035
            elseif occursin(r"(2051|2065|2070)", run_params.futurePeriod[j])
                Year = 2065
            else
                @error "Future period not recognised"
            end

            # Set starting dates as the first of every month   
            dates = [Date(Year, m, 01) for m in 1:12]

            for i in eachindex(run_params.rcp)
                filename = filter(x -> occursin(r"^" * speciesName[1] * "_" * run_params.country *
                                                "_rcp" * run_params.rcp[i] * "_" * run_params.futurePeriod[j] * "_1km.jld2", x),
                    readdir(joinpath(paths.resultsDir, speciesName[1])))

                if length(filename) > 1
                    @error "More than one input file found"
                end

                push!(inFiles, joinpath(paths.resultsDir, speciesName[1], filename[1]))
                push!(yearStrVec, "rcp" * run_params.rcp[i] * "_" * run_params.futurePeriod[j])
                push!(yearVec, Year)
            end
        end
    else

        # Create vector of files to import for past climates
        for y in eachindex(run_params.years)
            filename = filter(x -> occursin(r"^" * speciesName[1] * "_" * run_params.country * "_" * string(run_params.years[y]) * "_1km.jld2", x),
                readdir(joinpath(paths.resultsDir, speciesName[1])))

            if length(filename) > 1
                @error "More than one input file found"
            else
                push!(inFiles, joinpath(paths.resultsDir, speciesName[1], filename[1]))
            end
            push!(yearVec, run_params.years[y])
            push!(yearStrVec, string(run_params.years[y]))
        end

    end

    # =========================================================
    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    # Import the averaged data
    aggFile = joinpath(paths.resultsDir, speciesName[1], "average_" * speciesName[1] * "_" *
                                                         run_params.thirty_years * "_1km.csv")
    d_agg = CSV.read(aggFile, DataFrame, missingstring="NA")




    # =========================================================
    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    # Import and process individual year data

    for f in eachindex(inFiles)

        # Import the data from the jld2 files
        println("  ")
        @info "Importing data for " * yearStrVec[f] 
        df_tmp = read_OPRAM_JLD2(inFiles[f], yearVec[f], grid)

        # df_1km = DataFrame()
        if run_params.TRANSLATE_future
            # If TRANSLATE future data then calculate the average across replicates

            # Group data frame by location and then starting Date 
            df_group = groupby(df_tmp, [:ID, :startMonth])

            # Calculate average over all replicates
            df_1km = combine(df_group,
                :nGenerations => (x -> mean(x)) => :nGenerations,          # Mean generations
                :emergeDOY => (x -> mean(x)) => :emergeDOY)                # Mean emergence DOY

            df_1km.startDate = Date.(yearVec[f], df_1km.startMonth, 1)

            df_group = nothing  # Remove df_group

        else
            # If not TRANSLATE future data then just use the imported data
            df_1km = df_tmp
        end
        df_tmp = nothing  # Remove df_tmp







        # =========================================================
        # =========================================================
        # Combine the multi year median with the original data and calculate anomalies

        @info "---- Calculating anomalies"

        # Combine origninal data frame with 30 year average
        leftjoin!(df_1km, select(d_agg, Not([:east, :north])), on=[:ID, :startMonth])

        # Calculate anomalies
        transform!(df_1km, [:nGenerations, :nGenerations_median] => ((a, b) -> a .- b) => :nGenerations_anomaly)
        transform!(df_1km, [:emergeDOY, :emergeDOY_median] => ((a, b) -> a .- b) => :emergeDOY_anomaly)


        # =========================================================
        # =========================================================
        # Export the anomaly and multi year average using a separate file for every year and every county

        @info "---- Writing 1km results to CSV files"
        save_OPRAM_1km_CSV(df_1km, grid, speciesName[1], yearStrVec[f], paths)



        # =========================================================
        # =========================================================
        # Create 10km summary ---------

        @info "---- Aggregating data to 10km resolution"
        df_10km = aggregate_to_hectad(df_1km)




        # =========================================================
        # =========================================================
        # Export 10km summary for the anomaly and multi year average
        @info "---- Writing 10km data for year " * yearStrVec[f]
        save_OPRAM_10km_CSV(df_10km, grid, speciesName[1], yearStrVec[f], paths)
    end


    # Clear data for this species
    # out_10km = nothing
    df_10km = nothing
    df_group = nothing
    df_1km = nothing
    df_agg = nothing


    # Print blank line
    println(" ")
end
